Title,Authors,Published Date,Abstract,URL,Official Categories,Categories_0.5,Categories_0.6,Categories_0.7,Categories_0.8,Categories_0.9
Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages,"Max Zuo, Francisco Piedrahita Velez, Xiaochen Li, Michael L. Littman, Stephen H. Bach",2024-07-03,"Many recent works have explored using language models for planning problems. One line of research focuses on translating natural language descriptions of planning tasks into structured planning languages, such as the planning domain definition language (PDDL). While this approach is promising, accurately measuring the quality of generated PDDL code continues to pose significant challenges. First, generated PDDL code is typically evaluated using planning validators that check whether the problem can be solved with a planner. This method is insufficient because a language model might generate valid PDDL code that does not align with the natural language description of the task. Second, existing evaluation sets often have natural language descriptions of the planning task that closely resemble the ground truth PDDL, reducing the challenge of the task. To bridge this gap, we introduce \benchmarkName, a benchmark designed to evaluate language models' ability to generate PDDL code from natural language descriptions of planning tasks. We begin by creating a PDDL equivalence algorithm that rigorously evaluates the correctness of PDDL code generated by language models by flexibly comparing it against a ground truth PDDL. Then, we present a dataset of $132,037$ text-to-PDDL pairs across 13 different tasks, with varying levels of difficulty. Finally, we evaluate several API-access and open-weight language models that reveal this task's complexity. For example, $87.6\%$ of the PDDL problem descriptions generated by GPT-4o are syntactically parseable, $82.2\%$ are valid, solve-able problems, but only $35.1\%$ are semantically correct, highlighting the need for a more rigorous benchmark for this problem.",http://arxiv.org/abs/2407.03321v1,"cs.CL, cs.AI, cs.LG","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['plan-generation', 'language-translation', 'interactive-planning']",['language-translation'],['Unclassified']
Automated radiotherapy treatment planning guided by GPT-4Vision,"Sheng Liu, Oscar Pastor-Serrano, Yizheng Chen, Matthew Gopaulchan, Weixing Liang, Mark Buyyounouski, Erqi Pollom, Quynh-Thu Le, Michael Gensheimer, Peng Dong, Yong Yang, James Zou, Lei Xing",2024-06-21,"Radiotherapy treatment planning is a time-consuming and potentially subjective process that requires the iterative adjustment of model parameters to balance multiple conflicting objectives. Recent advancements in large foundation models offer promising avenues for addressing the challenges in planning and clinical decision-making. This study introduces GPT-RadPlan, a fully automated treatment planning framework that harnesses prior radiation oncology knowledge encoded in multi-modal large language models, such as GPT-4Vision (GPT-4V) from OpenAI. GPT-RadPlan is made aware of planning protocols as context and acts as an expert human planner, capable of guiding a treatment planning process. Via in-context learning, we incorporate clinical protocols for various disease sites as prompts to enable GPT-4V to acquire treatment planning domain knowledge. The resulting GPT-RadPlan agent is integrated into our in-house inverse treatment planning system through an API. The efficacy of the automated planning system is showcased using multiple prostate and head & neck cancer cases, where we compared GPT-RadPlan results to clinical plans. In all cases, GPT-RadPlan either outperformed or matched the clinical plans, demonstrating superior target coverage and organ-at-risk sparing. Consistently satisfying the dosimetric objectives in the clinical protocol, GPT-RadPlan represents the first multimodal large language model agent that mimics the behaviors of human planners in radiation oncology clinics, achieving remarkable results in automating the treatment planning process without the need for additional training.",http://arxiv.org/abs/2406.15609v2,"physics.med-ph, cs.AI","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']",['Unclassified'],['Unclassified'],['Unclassified'],['Unclassified']
RePrompt: Planning by Automatic Prompt Engineering for Large Language Models Agents,"Weizhe Chen, Sven Koenig, Bistra Dilkina",2024-06-17,"In this past year, large language models (LLMs) have had remarkable success in domains outside the traditional natural language processing, and people are starting to explore the usage of LLMs in more general and close to application domains like code generation, travel planning, and robot controls. Connecting these LLMs with great capacity and external tools, people are building the so-called LLM agents, which are supposed to help people do all kinds of work in everyday life. In all these domains, the prompt to the LLMs has been shown to make a big difference in what the LLM would generate and thus affect the performance of the LLM agents. Therefore, automatic prompt engineering has become an important question for many researchers and users of LLMs. In this paper, we propose a novel method, \textsc{RePrompt}, which does ""gradient descent"" to optimize the step-by-step instructions in the prompt of the LLM agents based on the chat history obtained from interactions with LLM agents. By optimizing the prompt, the LLM will learn how to plan in specific domains. We have used experiments in PDDL generation and travel planning to show that our method could generally improve the performance for different reasoning tasks when using the updated prompt as the initial prompt.",http://arxiv.org/abs/2406.11132v1,"cs.CL, cs.AI, cs.LG","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'interactive-planning', 'plan-generation']",['Unclassified'],['Unclassified']
DAG-Plan: Generating Directed Acyclic Dependency Graphs for Dual-Arm Cooperative Planning,"Zeyu Gao, Yao Mu, Jinye Qu, Mengkang Hu, Lingyue Guo, Ping Luo, Yanfeng Lu",2024-06-14,"Dual-arm robots offer enhanced versatility and efficiency over single-arm counterparts by enabling concurrent manipulation of multiple objects or cooperative execution of tasks using both arms. However, effectively coordinating the two arms for complex long-horizon tasks remains a significant challenge. Existing task planning methods predominantly focus on single-arm robots or rely on predefined bimanual operations, failing to fully leverage the capabilities of dual-arm systems. To address this limitation, we introduce DAG-Plan, a structured task planning framework tailored for dual-arm robots. DAG-Plan harnesses large language models (LLMs) to decompose intricate tasks into actionable sub-tasks represented as nodes within a directed acyclic graph (DAG). Critically, DAG-Plan dynamically assigns these sub-tasks to the appropriate arm based on real-time environmental observations, enabling parallel and adaptive execution. We evaluate DAG-Plan on the novel Dual-Arm Kitchen Benchmark, comprising 9 sequential tasks with 78 sub-tasks and 26 objects. Extensive experiments demonstrate the superiority of DAG-Plan over directly using LLM to generate plans, achieving nearly 50% higher efficiency compared to the single-arm task planning baseline and nearly double the success rate of the dual-arm task planning baseline.",http://arxiv.org/abs/2406.09953v2,"cs.RO, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']",['Unclassified'],['Unclassified'],['Unclassified']
CLMASP: Coupling Large Language Models with Answer Set Programming for Robotic Task Planning,"Xinrui Lin, Yangfan Wu, Huanyu Yang, Yu Zhang, Yanyong Zhang, Jianmin Ji",2024-06-05,"Large Language Models (LLMs) possess extensive foundational knowledge and moderate reasoning abilities, making them suitable for general task planning in open-world scenarios. However, it is challenging to ground a LLM-generated plan to be executable for the specified robot with certain restrictions. This paper introduces CLMASP, an approach that couples LLMs with Answer Set Programming (ASP) to overcome the limitations, where ASP is a non-monotonic logic programming formalism renowned for its capacity to represent and reason about a robot's action knowledge. CLMASP initiates with a LLM generating a basic skeleton plan, which is subsequently tailored to the specific scenario using a vector database. This plan is then refined by an ASP program with a robot's action knowledge, which integrates implementation details into the skeleton, grounding the LLM's abstract outputs in practical robot contexts. Our experiments conducted on the VirtualHome platform demonstrate CLMASP's efficacy. Compared to the baseline executable rate of under 2% with LLM approaches, CLMASP significantly improves this to over 90%.",http://arxiv.org/abs/2406.03367v1,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['plan-generation', 'model-construction', 'language-translation']",['Unclassified'],['Unclassified']
GameVLM: A Decision-making Framework for Robotic Task Planning Based on Visual Language Models and Zero-sum Games,"Aoran Mei, Jianhua Wang, Guo-Niu Zhu, Zhongxue Gan",2024-05-22,"With their prominent scene understanding and reasoning capabilities, pre-trained visual-language models (VLMs) such as GPT-4V have attracted increasing attention in robotic task planning. Compared with traditional task planning strategies, VLMs are strong in multimodal information parsing and code generation and show remarkable efficiency. Although VLMs demonstrate great potential in robotic task planning, they suffer from challenges like hallucination, semantic complexity, and limited context. To handle such issues, this paper proposes a multi-agent framework, i.e., GameVLM, to enhance the decision-making process in robotic task planning. In this study, VLM-based decision and expert agents are presented to conduct the task planning. Specifically, decision agents are used to plan the task, and the expert agent is employed to evaluate these task plans. Zero-sum game theory is introduced to resolve inconsistencies among different agents and determine the optimal solution. Experimental results on real robots demonstrate the efficacy of the proposed framework, with an average success rate of 83.3%.",http://arxiv.org/abs/2405.13751v1,"cs.RO, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['multiagent-planning', 'model-construction']",['Unclassified'],['Unclassified']
LLM+Reasoning+Planning for supporting incomplete user queries in presence of APIs,"Sudhir Agarwal, Anu Sreepathy, David H. Alonso, Prarit Lamba",2024-05-21,"Recent availability of Large Language Models (LLMs) has led to the development of numerous LLM-based approaches aimed at providing natural language interfaces for various end-user tasks. These end-user tasks in turn can typically be accomplished by orchestrating a given set of APIs. In practice, natural language task requests (user queries) are often incomplete, i.e., they may not contain all the information required by the APIs. While LLMs excel at natural language processing (NLP) tasks, they frequently hallucinate on missing information or struggle with orchestrating the APIs. The key idea behind our proposed approach is to leverage logical reasoning and classical AI planning along with an LLM for accurately answering user queries including identification and gathering of any missing information in these queries. Our approach uses an LLM and ASP (Answer Set Programming) solver to translate a user query to a representation in Planning Domain Definition Language (PDDL) via an intermediate representation in ASP. We introduce a special API ""get_info_api"" for gathering missing information. We model all the APIs as PDDL actions in a way that supports dataflow between the APIs. Our approach then uses a classical AI planner to generate an orchestration of API calls (including calls to get_info_api) to answer the user query. Our evaluation results show that our approach significantly outperforms a pure LLM based approach by achieving over 95\% success rate in most cases on a dataset containing complete and incomplete single goal and multi-goal queries where the multi-goal queries may or may not require dataflow among the APIs.",http://arxiv.org/abs/2405.12433v1,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'model-construction', 'interactive-planning', 'plan-generation']",['language-translation'],['Unclassified'],['Unclassified']
NL2Plan: Robust LLM-Driven Planning from Minimal Text Descriptions,"Elliot Gestrin, Marco Kuhlmann, Jendrik Seipp",2024-05-07,"Today's classical planners are powerful, but modeling input tasks in formats such as PDDL is tedious and error-prone. In contrast, planning with Large Language Models (LLMs) allows for almost any input text, but offers no guarantees on plan quality or even soundness. In an attempt to merge the best of these two approaches, some work has begun to use LLMs to automate parts of the PDDL creation process. However, these methods still require various degrees of expert input. We present NL2Plan, the first domain-agnostic offline LLM-driven planning system. NL2Plan uses an LLM to incrementally extract the necessary information from a short text prompt before creating a complete PDDL description of both the domain and the problem, which is finally solved by a classical planner. We evaluate NL2Plan on four planning domains and find that it solves 10 out of 15 tasks - a clear improvement over a plain chain-of-thought reasoning LLM approach, which only solves 2 tasks. Moreover, in two out of the five failure cases, instead of returning an invalid plan, NL2Plan reports that it failed to solve the task. In addition to using NL2Plan in end-to-end mode, users can inspect and correct all of its intermediate results, such as the PDDL representation, increasing explainability and making it an assistive tool for PDDL creation.",http://arxiv.org/abs/2405.04215v1,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'model-construction', 'interactive-planning', 'plan-generation']","['language-translation', 'interactive-planning']",['Unclassified']
Generating consistent PDDL domains with Large Language Models,"Pavel Smirnov, Frank Joublin, Antonello Ceravola, Michael Gienger",2024-04-11,"Large Language Models (LLMs) are capable of transforming natural language domain descriptions into plausibly looking PDDL markup. However, ensuring that actions are consistent within domains still remains a challenging task. In this paper we present a novel concept to significantly improve the quality of LLM-generated PDDL models by performing automated consistency checking during the generation process. Although the proposed consistency checking strategies still can't guarantee absolute correctness of generated models, they can serve as valuable source of feedback reducing the amount of correction efforts expected from a human in the loop. We demonstrate the capabilities of our error detection approach on a number of classical and custom planning domains (logistics, gripper, tyreworld, household, pizza).",http://arxiv.org/abs/2404.07751v1,"cs.RO, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'model-construction', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'plan-generation', 'language-translation', 'interactive-planning']","['language-translation', 'interactive-planning']",['Unclassified'],['Unclassified']
The Case for Developing a Foundation Model for Planning-like Tasks from Scratch,"Biplav Srivastava, Vishal Pallagani",2024-04-06,"Foundation Models (FMs) have revolutionized many areas of computing, including Automated Planning and Scheduling (APS). For example, a recent study found them useful for planning problems: plan generation, language translation, model construction, multi-agent planning, interactive planning, heuristics optimization, tool integration, and brain-inspired planning. Besides APS, there are many seemingly related tasks involving the generation of a series of actions with varying guarantees of their executability to achieve intended goals, which we collectively call planning-like (PL) tasks like business processes, programs, workflows, and guidelines, where researchers have considered using FMs. However, previous works have primarily focused on pre-trained, off-the-shelf FMs and optionally fine-tuned them. This paper discusses the need for a comprehensive FM for PL tasks from scratch and explores its design considerations. We argue that such an FM will open new and efficient avenues for PL problem-solving, just like LLMs are creating for APS.",http://arxiv.org/abs/2404.04540v1,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']",['plan-generation'],['Unclassified'],['Unclassified']
DELTA: Decomposed Efficient Long-Term Robot Task Planning using Large Language Models,"Yuchen Liu, Luigi Palmieri, Sebastian Koch, Ilche Georgievski, Marco Aiello",2024-04-04,"Recent advancements in Large Language Models (LLMs) have sparked a revolution across various research fields. In particular, the integration of common-sense knowledge from LLMs into robot task and motion planning has been proven to be a game-changer, elevating performance in terms of explainability and downstream task efficiency to unprecedented heights. However, managing the vast knowledge encapsulated within these large models has posed challenges, often resulting in infeasible plans generated by LLM-based planning systems due to hallucinations or missing domain information. To overcome these challenges and obtain even greater planning feasibility and computational efficiency, we propose a novel LLM-driven task planning approach called DELTA. For achieving better grounding from environmental topology into actionable knowledge, DELTA leverages the power of scene graphs as environment representations within LLMs, enabling the fast generation of precise planning problem descriptions. For obtaining higher planning performance, we use LLMs to decompose the long-term task goals into an autoregressive sequence of sub-goals for an automated task planner to solve. Our contribution enables a more efficient and fully automatic task planning pipeline, achieving higher planning success rates and significantly shorter planning times compared to the state of the art.",http://arxiv.org/abs/2404.03275v1,"cs.RO, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'plan-generation', 'language-translation', 'interactive-planning']",['Unclassified']
A Survey of Optimization-based Task and Motion Planning: From Classical To Learning Approaches,"Zhigen Zhao, Shuo Cheng, Yan Ding, Ziyi Zhou, Shiqi Zhang, Danfei Xu, Ye Zhao",2024-04-03,"Task and Motion Planning (TAMP) integrates high-level task planning and low-level motion planning to equip robots with the autonomy to effectively reason over long-horizon, dynamic tasks. Optimization-based TAMP focuses on hybrid optimization approaches that define goal conditions via objective functions and are capable of handling open-ended goals, robotic dynamics, and physical interaction between the robot and the environment. Therefore, optimization-based TAMP is particularly suited to solve highly complex, contact-rich locomotion and manipulation problems. This survey provides a comprehensive review on optimization-based TAMP, covering (i) planning domain representations, including action description languages and temporal logic, (ii) individual solution strategies for components of TAMP, including AI planning and trajectory optimization (TO), and (iii) the dynamic interplay between logic-based task planning and model-based TO. A particular focus of this survey is to highlight the algorithm structures to efficiently solve TAMP, especially hierarchical and distributed approaches. Additionally, the survey emphasizes the synergy between the classical methods and contemporary learning-based innovations such as large language models. Furthermore, the future research directions for TAMP is discussed in this survey, highlighting both algorithmic and application-specific challenges.",http://arxiv.org/abs/2404.02817v4,"cs.RO, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']",['plan-generation'],['Unclassified'],['Unclassified']
Large Language Models as Planning Domain Generators,"James Oswald, Kavitha Srinivas, Harsha Kokel, Junkyu Lee, Michael Katz, Shirin Sohrabi",2024-04-02,"Developing domain models is one of the few remaining places that require manual human labor in AI planning. Thus, in order to make planning more accessible, it is desirable to automate the process of domain model generation. To this end, we investigate if large language models (LLMs) can be used to generate planning domain models from simple textual descriptions. Specifically, we introduce a framework for automated evaluation of LLM-generated domains by comparing the sets of plans for domain instances. Finally, we perform an empirical analysis of 7 large language models, including coding and chat models across 9 different planning domains, and under three classes of natural language domain descriptions. Our results indicate that LLMs, particularly those with high parameter counts, exhibit a moderate level of proficiency in generating correct planning domains from natural language descriptions. Our code is available at https://github.com/IBM/NL2PDDL.",http://arxiv.org/abs/2405.06650v1,"cs.CL, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'model-construction', 'interactive-planning', 'plan-generation']",['Unclassified'],['Unclassified']
TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models,"Ishika Singh, David Traum, Jesse Thomason",2024-03-25,"Classical planning formulations like the Planning Domain Definition Language (PDDL) admit action sequences guaranteed to achieve a goal state given an initial state if any are possible. However, reasoning problems defined in PDDL do not capture temporal aspects of action taking, for example that two agents in the domain can execute an action simultaneously if postconditions of each do not interfere with preconditions of the other. A human expert can decompose a goal into largely independent constituent parts and assign each agent to one of these subgoals to take advantage of simultaneous actions for faster execution of plan steps, each using only single agent planning. By contrast, large language models (LLMs) used for directly inferring plan steps do not guarantee execution success, but do leverage commonsense reasoning to assemble action sequences. We combine the strengths of classical planning and LLMs by approximating human intuitions for two-agent planning goal decomposition. We demonstrate that LLM-based goal decomposition leads to faster planning times than solving multi-agent PDDL problems directly while simultaneously achieving fewer plan execution steps than a single agent plan alone and preserving execution success. Additionally, we find that LLM-based approximations of subgoals can achieve similar multi-agent execution steps than those specified by human experts. Website and resources at https://glamor-usc.github.io/twostep",http://arxiv.org/abs/2403.17246v1,"cs.AI, cs.CL, cs.MA, cs.RO","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']",['language-translation'],['Unclassified']
LLM3:Large Language Model-based Task and Motion Planning with Motion Failure Reasoning,"Shu Wang, Muzhi Han, Ziyuan Jiao, Zeyu Zhang, Ying Nian Wu, Song-Chun Zhu, Hangxin Liu",2024-03-18,"Conventional Task and Motion Planning (TAMP) approaches rely on manually crafted interfaces connecting symbolic task planning with continuous motion generation. These domain-specific and labor-intensive modules are limited in addressing emerging tasks in real-world settings. Here, we present LLM^3, a novel Large Language Model (LLM)-based TAMP framework featuring a domain-independent interface. Specifically, we leverage the powerful reasoning and planning capabilities of pre-trained LLMs to propose symbolic action sequences and select continuous action parameters for motion planning. Crucially, LLM^3 incorporates motion planning feedback through prompting, allowing the LLM to iteratively refine its proposals by reasoning about motion failure. Consequently, LLM^3 interfaces between task planning and motion planning, alleviating the intricate design process of handling domain-specific messages between them. Through a series of simulations in a box-packing domain, we quantitatively demonstrate the effectiveness of LLM^3 in solving TAMP problems and the efficiency in selecting action parameters. Ablation studies underscore the significant contribution of motion failure reasoning to the success of LLM^3. Furthermore, we conduct qualitative experiments on a physical manipulator, demonstrating the practical applicability of our approach in real-world settings.",http://arxiv.org/abs/2403.11552v3,"cs.RO, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['plan-generation', 'language-translation']",['Unclassified'],['Unclassified']
Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping,"Lucas Lehnert, Sainbayar Sukhbaatar, DiJia Su, Qinqing Zheng, Paul Mcvay, Michael Rabbat, Yuandong Tian",2024-02-21,"While Transformers have enabled tremendous progress in various application settings, such architectures still trail behind traditional symbolic planners for solving complex decision making tasks. In this work, we demonstrate how to train Transformers to solve complex planning tasks. This is accomplished by training an encoder-decoder Transformer model to predict the search dynamics of the $A^*$ search algorithm. We fine tune this model to obtain a Searchformer, a Transformer model that optimally solves previously unseen Sokoban puzzles 93.7% of the time, while using up to 26.8% fewer search steps than the $A^*$ implementation that was used for training initially. In our training method, $A^*$'s search dynamics are expressed as a token sequence outlining when task states are added and removed into the search tree during symbolic planning. Searchformer significantly outperforms baselines that predict the optimal plan directly with a 5-10$\times$ smaller model size and a 10$\times$ smaller training dataset. Lastly, we demonstrate how Searchformer scales to larger and more complex decision making tasks with improved percentage of solved tasks and shortened search dynamics.",http://arxiv.org/abs/2402.14083v2,cs.AI,"['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'plan-generation']",['Unclassified'],['Unclassified'],['Unclassified']
AutoGPT+P: Affordance-based Task Planning with Large Language Models,"Timo Birr, Christoph Pohl, Abdelrahman Younes, Tamim Asfour",2024-02-16,"Recent advances in task planning leverage Large Language Models (LLMs) to improve generalizability by combining such models with classical planning algorithms to address their inherent limitations in reasoning capabilities. However, these approaches face the challenge of dynamically capturing the initial state of the task planning problem. To alleviate this issue, we propose AutoGPT+P, a system that combines an affordance-based scene representation with a planning system. Affordances encompass the action possibilities of an agent on the environment and objects present in it. Thus, deriving the planning domain from an affordance-based scene representation allows symbolic planning with arbitrary objects. AutoGPT+P leverages this representation to derive and execute a plan for a task specified by the user in natural language. In addition to solving planning tasks under a closed-world assumption, AutoGPT+P can also handle planning with incomplete information, e. g., tasks with missing objects by exploring the scene, suggesting alternatives, or providing a partial plan. The affordance-based scene representation combines object detection with an automatically generated object-affordance-mapping using ChatGPT. The core planning tool extends existing work by automatically correcting semantic and syntactic errors. Our approach achieves a success rate of 98%, surpassing the current 81% success rate of the current state-of-the-art LLM-based planning method SayCan on the SayCan instruction set. Furthermore, we evaluated our approach on our newly created dataset with 150 scenarios covering a wide range of complex tasks with missing objects, achieving a success rate of 79% on our dataset. The dataset and the code are publicly available at https://git.h2t.iar.kit.edu/birr/autogpt-p-standalone.",http://arxiv.org/abs/2402.10778v2,"cs.RO, cs.AI, I.2","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'model-construction', 'interactive-planning', 'plan-generation']",['Unclassified'],['Unclassified']
LoTa-Bench: Benchmarking Language-oriented Task Planners for Embodied Agents,"Jae-Woo Choi, Youngwoo Yoon, Hyobin Ong, Jaehong Kim, Minsu Jang",2024-02-13,"Large language models (LLMs) have recently received considerable attention as alternative solutions for task planning. However, comparing the performance of language-oriented task planners becomes difficult, and there exists a dearth of detailed exploration regarding the effects of various factors such as pre-trained model selection and prompt construction. To address this, we propose a benchmark system for automatically quantifying performance of task planning for home-service embodied agents. Task planners are tested on two pairs of datasets and simulators: 1) ALFRED and AI2-THOR, 2) an extension of Watch-And-Help and VirtualHome. Using the proposed benchmark system, we perform extensive experiments with LLMs and prompts, and explore several enhancements of the baseline planner. We expect that the proposed benchmark tool would accelerate the development of language-oriented task planners.",http://arxiv.org/abs/2402.08178v1,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['tool-integration', 'plan-generation', 'language-translation', 'interactive-planning']",['plan-generation'],['Unclassified']
"TIC: Translate-Infer-Compile for accurate ""text to plan"" using LLMs and Logical Representations","Sudhir Agarwal, Anu Sreepathy",2024-02-09,"We study the problem of generating plans for given natural language planning task requests. On one hand, LLMs excel at natural language processing but do not perform well on planning. On the other hand, classical planning tools excel at planning tasks but require input in a structured language such as the Planning Domain Definition Language (PDDL). We leverage the strengths of both the techniques by using an LLM for generating the PDDL representation (task PDDL) of planning task requests followed by using a classical planner for computing a plan. Unlike previous approaches that use LLMs for generating task PDDLs directly, our approach comprises of (a) translate: using an LLM only for generating a logically interpretable intermediate representation of natural language task description, (b) infer: deriving additional logically dependent information from the intermediate representation using a logic reasoner (currently, Answer Set Programming solver), and (c) compile: generating the target task PDDL from the base and inferred information. We observe that using an LLM to only output the intermediate representation significantly reduces LLM errors. Consequently, TIC approach achieves, for at least one LLM, high accuracy on task PDDL generation for all seven domains of our evaluation dataset.",http://arxiv.org/abs/2402.06608v2,"cs.CL, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['plan-generation', 'model-construction', 'language-translation', 'interactive-planning']",['language-translation'],['Unclassified']
Consolidating Trees of Robotic Plans Generated Using Large Language Models to Improve Reliability,"Md Sadman Sakib, Yu Sun",2024-01-15,"The inherent probabilistic nature of Large Language Models (LLMs) introduces an element of unpredictability, raising concerns about potential discrepancies in their output. This paper introduces an innovative approach aims to generate correct and optimal robotic task plans for diverse real-world demands and scenarios. LLMs have been used to generate task plans, but they are unreliable and may contain wrong, questionable, or high-cost steps. The proposed approach uses LLM to generate a number of task plans as trees and amalgamates them into a graph by removing questionable paths. Then an optimal task tree can be retrieved to circumvent questionable and high-cost nodes, thereby improving planning accuracy and execution efficiency. The approach is further improved by incorporating a large knowledge network. Leveraging GPT-4 further, the high-level task plan is converted into a low-level Planning Domain Definition Language (PDDL) plan executable by a robot. Evaluation results highlight the superior accuracy and efficiency of our approach compared to previous methodologies in the field of task planning.",http://arxiv.org/abs/2401.07868v1,"cs.RO, cs.AI, cs.CL","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['plan-generation', 'language-translation']",['Unclassified']
"Large Language Models for Robotics: Opportunities, Challenges, and Perspectives","Jiaqi Wang, Zihao Wu, Yiwei Li, Hanqi Jiang, Peng Shu, Enze Shi, Huawen Hu, Chong Ma, Yiheng Liu, Xuhui Wang, Yincheng Yao, Xuan Liu, Huaqin Zhao, Zhengliang Liu, Haixing Dai, Lin Zhao, Bao Ge, Xiang Li, Tianming Liu, Shu Zhang",2024-01-09,"Large language models (LLMs) have undergone significant expansion and have been increasingly integrated across various domains. Notably, in the realm of robot task planning, LLMs harness their advanced reasoning and language comprehension capabilities to formulate precise and efficient action plans based on natural language instructions. However, for embodied tasks, where robots interact with complex environments, text-only LLMs often face challenges due to a lack of compatibility with robotic visual perception. This study provides a comprehensive overview of the emerging integration of LLMs and multimodal LLMs into various robotic tasks. Additionally, we propose a framework that utilizes multimodal GPT-4V to enhance embodied task planning through the combination of natural language instructions and robot visual perceptions. Our results, based on diverse datasets, indicate that GPT-4V effectively enhances robot performance in embodied tasks. This extensive survey and evaluation of LLMs and multimodal LLMs across a variety of robotic tasks enriches the understanding of LLM-centric embodied intelligence and provides forward-looking insights toward bridging the gap in Human-Robot-Environment interaction.",http://arxiv.org/abs/2401.04334v1,"cs.RO, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['plan-generation', 'model-construction', 'language-translation', 'interactive-planning']",['Unclassified'],['Unclassified']
On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS),"Vishal Pallagani, Kaushik Roy, Bharath Muppasani, Francesco Fabiano, Andrea Loreggia, Keerthiram Murugesan, Biplav Srivastava, Francesca Rossi, Lior Horesh, Amit Sheth",2024-01-04,"Automated Planning and Scheduling is among the growing areas in Artificial Intelligence (AI) where mention of LLMs has gained popularity. Based on a comprehensive review of 126 papers, this paper investigates eight categories based on the unique applications of LLMs in addressing various aspects of planning problems: language translation, plan generation, model construction, multi-agent planning, interactive planning, heuristics optimization, tool integration, and brain-inspired planning. For each category, we articulate the issues considered and existing gaps. A critical insight resulting from our review is that the true potential of LLMs unfolds when they are integrated with traditional symbolic planners, pointing towards a promising neuro-symbolic approach. This approach effectively combines the generative aspects of LLMs with the precision of classical planning methods. By synthesizing insights from existing literature, we underline the potential of this integration to address complex planning challenges. Our goal is to encourage the ICAPS community to recognize the complementary strengths of LLMs and symbolic planners, advocating for a direction in automated planning that leverages these synergistic capabilities to develop more advanced and intelligent planning systems.",http://arxiv.org/abs/2401.02500v2,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'brain-inspired-planning', 'plan-generation', 'language-translation']",['Unclassified'],['Unclassified']
Look Before You Leap: Unveiling the Power of GPT-4V in Robotic Vision-Language Planning,"Yingdong Hu, Fanqi Lin, Tong Zhang, Li Yi, Yang Gao",2023-11-29,"In this study, we are interested in imbuing robots with the capability of physically-grounded task planning. Recent advancements have shown that large language models (LLMs) possess extensive knowledge useful in robotic tasks, especially in reasoning and planning. However, LLMs are constrained by their lack of world grounding and dependence on external affordance models to perceive environmental information, which cannot jointly reason with LLMs. We argue that a task planner should be an inherently grounded, unified multimodal system. To this end, we introduce Robotic Vision-Language Planning (ViLa), a novel approach for long-horizon robotic planning that leverages vision-language models (VLMs) to generate a sequence of actionable steps. ViLa directly integrates perceptual data into its reasoning and planning process, enabling a profound understanding of commonsense knowledge in the visual world, including spatial layouts and object attributes. It also supports flexible multimodal goal specification and naturally incorporates visual feedback. Our extensive evaluation, conducted in both real-robot and simulated environments, demonstrates ViLa's superiority over existing LLM-based planners, highlighting its effectiveness in a wide array of open-world manipulation tasks.",http://arxiv.org/abs/2311.17842v2,"cs.RO, cs.AI, cs.CL, cs.CV, cs.LG","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['plan-generation', 'model-construction', 'language-translation']",['Unclassified']
Can LLMs Fix Issues with Reasoning Models? Towards More Likely Models for AI Planning,"Turgay Caglar, Sirine Belhaj, Tathagata Chakraborti, Michael Katz, Sarath Sreedharan",2023-11-22,"This is the first work to look at the application of large language models (LLMs) for the purpose of model space edits in automated planning tasks. To set the stage for this union, we explore two different flavors of model space problems that have been studied in the AI planning literature and explore the effect of an LLM on those tasks. We empirically demonstrate how the performance of an LLM contrasts with combinatorial search (CS) -- an approach that has been traditionally used to solve model space tasks in planning, both with the LLM in the role of a standalone model space reasoner as well as in the role of a statistical signal in concert with the CS approach as part of a two-stage process. Our experiments show promising results suggesting further forays of LLMs into the exciting world of model space reasoning for planning tasks in the future.",http://arxiv.org/abs/2311.13720v2,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'plan-generation', 'model-construction', 'language-translation']",['Unclassified'],['Unclassified']
Physical Reasoning and Object Planning for Household Embodied Agents,"Ayush Agrawal, Raghav Prabhakar, Anirudh Goyal, Dianbo Liu",2023-11-22,"In this study, we explore the sophisticated domain of task planning for robust household embodied agents, with a particular emphasis on the intricate task of selecting substitute objects. We introduce the CommonSense Object Affordance Task (COAT), a novel framework designed to analyze reasoning capabilities in commonsense scenarios. This approach is centered on understanding how these agents can effectively identify and utilize alternative objects when executing household tasks, thereby offering insights into the complexities of practical decision-making in real-world environments.Drawing inspiration from human decision-making, we explore how large language models tackle this challenge through three meticulously crafted commonsense question-and-answer datasets, featuring refined rules and human annotations. Our evaluation of state-of-the-art language models on these datasets sheds light on three pivotal considerations: 1) aligning an object's inherent utility with the task at hand, 2) navigating contextual dependencies (societal norms, safety, appropriateness, and efficiency), and 3) accounting for the current physical state of the object. To maintain accessibility, we introduce five abstract variables reflecting an object's physical condition, modulated by human insights to simulate diverse household scenarios. Our contributions include insightful Object-Utility mappings addressing the first consideration and two extensive QA datasets (15k and 130k questions) probing the intricacies of contextual dependencies and object states. The datasets, along with our findings, are accessible at: \url{https://github.com/com-phy-affordance/COAT}. This research not only advances our understanding of physical commonsense reasoning in language models but also paves the way for future improvements in household agent intelligence.",http://arxiv.org/abs/2311.13577v1,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['plan-generation', 'model-construction', 'language-translation', 'interactive-planning']",['plan-generation'],['Unclassified'],['Unclassified']
TPTU-v2: Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Systems,"Yilun Kong, Jingqing Ruan, Yihong Chen, Bin Zhang, Tianpeng Bao, Shiwei Shi, Guoqing Du, Xiaoru Hu, Hangyu Mao, Ziyue Li, Xingyu Zeng, Rui Zhao",2023-11-19,"Large Language Models (LLMs) have demonstrated proficiency in addressing tasks that necessitate a combination of task planning and the usage of external tools that require a blend of task planning and the utilization of external tools, such as APIs. However, real-world complex systems present three prevalent challenges concerning task planning and tool usage: (1) The real system usually has a vast array of APIs, so it is impossible to feed the descriptions of all APIs to the prompt of LLMs as the token length is limited; (2) the real system is designed for handling complex tasks, and the base LLMs can hardly plan a correct sub-task order and API-calling order for such tasks; (3) Similar semantics and functionalities among APIs in real systems create challenges for both LLMs and even humans in distinguishing between them. In response, this paper introduces a comprehensive framework aimed at enhancing the Task Planning and Tool Usage (TPTU) abilities of LLM-based agents operating within real-world systems. Our framework comprises three key components designed to address these challenges: (1) the API Retriever selects the most pertinent APIs for the user task among the extensive array available; (2) LLM Finetuner tunes a base LLM so that the finetuned LLM can be more capable for task planning and API calling; (3) the Demo Selector adaptively retrieves different demonstrations related to hard-to-distinguish APIs, which is further used for in-context learning to boost the final performance. We validate our methods using a real-world commercial system as well as an open-sourced academic dataset, and the outcomes clearly showcase the efficacy of each individual component as well as the integrated framework.",http://arxiv.org/abs/2311.11315v1,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']",['tool-integration'],['Unclassified'],['Unclassified']
AutoPlanBench: Automatically generating benchmarks for LLM planners from PDDL,"Katharina Stein, Daniel Fier, Jrg Hoffmann, Alexander Koller",2023-11-16,"LLMs are being increasingly used for planning-style tasks, but their capabilities for planning and reasoning are poorly understood. We present AutoPlanBench, a novel method for automatically converting planning benchmarks written in PDDL into textual descriptions and offer a benchmark dataset created with our method. We show that while the best LLM planners do well on some planning tasks, others remain out of reach of current methods.",http://arxiv.org/abs/2311.09830v2,"cs.AI, cs.CL","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['plan-generation', 'language-translation']",['Unclassified'],['Unclassified']
From Cooking Recipes to Robot Task Trees -- Improving Planning Correctness and Task Efficiency by Leveraging LLMs with a Knowledge Network,"Md Sadman Sakib, Yu Sun",2023-09-17,"Task planning for robotic cooking involves generating a sequence of actions for a robot to prepare a meal successfully. This paper introduces a novel task tree generation pipeline producing correct planning and efficient execution for cooking tasks. Our method first uses a large language model (LLM) to retrieve recipe instructions and then utilizes a fine-tuned GPT-3 to convert them into a task tree, capturing sequential and parallel dependencies among subtasks. The pipeline then mitigates the uncertainty and unreliable features of LLM outputs using task tree retrieval. We combine multiple LLM task tree outputs into a graph and perform a task tree retrieval to avoid questionable nodes and high-cost nodes to improve planning correctness and improve execution efficiency. Our evaluation results show its superior performance compared to previous works in task planning accuracy and efficiency.",http://arxiv.org/abs/2309.09181v1,"cs.RO, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']",['language-translation'],['language-translation'],['language-translation']
Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations,"Xu Huang, Jianxun Lian, Yuxuan Lei, Jing Yao, Defu Lian, Xing Xie",2023-08-31,"Recommender models excel at providing domain-specific item recommendations by leveraging extensive user behavior data. Despite their ability to act as lightweight domain experts, they struggle to perform versatile tasks such as providing explanations and engaging in conversations. On the other hand, large language models (LLMs) represent a significant step towards artificial general intelligence, showcasing remarkable capabilities in instruction comprehension, commonsense reasoning, and human interaction. However, LLMs lack the knowledge of domain-specific item catalogs and behavioral patterns, particularly in areas that diverge from general world knowledge, such as online e-commerce. Finetuning LLMs for each domain is neither economic nor efficient. In this paper, we bridge the gap between recommender models and LLMs, combining their respective strengths to create a versatile and interactive recommender system. We introduce an efficient framework called \textbf{InteRecAgent}, which employs LLMs as the brain and recommender models as tools. We first outline a minimal set of essential tools required to transform LLMs into InteRecAgent. We then propose an efficient workflow within InteRecAgent for task execution, incorporating key components such as memory components, dynamic demonstration-augmented task planning, and reflection. InteRecAgent enables traditional recommender systems, such as those ID-based matrix factorization models, to become interactive systems with a natural language interface through the integration of LLMs. Experimental results on several public datasets show that InteRecAgent achieves satisfying performance as a conversational recommender system, outperforming general-purpose LLMs. The source code of InteRecAgent is released at https://aka.ms/recagent.",http://arxiv.org/abs/2308.16505v3,"cs.IR, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'interactive-planning', 'plan-generation']",['Unclassified'],['Unclassified'],['Unclassified'],['Unclassified']
ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning,"Zhehua Zhou, Jiayang Song, Kunpeng Yao, Zhan Shu, Lei Ma",2023-08-26,"Motivated by the substantial achievements observed in Large Language Models (LLMs) in the field of natural language processing, recent research has commenced investigations into the application of LLMs for complex, long-horizon sequential task planning challenges in robotics. LLMs are advantageous in offering the potential to enhance the generalizability as task-agnostic planners and facilitate flexible interaction between human instructors and planning systems. However, task plans generated by LLMs often lack feasibility and correctness. To address this challenge, we introduce ISR-LLM, a novel framework that improves LLM-based planning through an iterative self-refinement process. The framework operates through three sequential steps: preprocessing, planning, and iterative self-refinement. During preprocessing, an LLM translator is employed to convert natural language input into a Planning Domain Definition Language (PDDL) formulation. In the planning phase, an LLM planner formulates an initial plan, which is then assessed and refined in the iterative self-refinement step by using a validator. We examine the performance of ISR-LLM across three distinct planning domains. The results show that ISR-LLM is able to achieve markedly higher success rates in task accomplishments compared to state-of-the-art LLM-based planners. Moreover, it also preserves the broad applicability and generalizability of working with natural language instructions.",http://arxiv.org/abs/2308.13724v1,"cs.RO, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']",['interactive-planning'],['interactive-planning']
SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge,"Rishi Hazra, Pedro Zuidberg Dos Martires, Luc De Raedt",2023-08-24,"Large Language Models (LLMs) have demonstrated impressive planning abilities due to their vast ""world knowledge"". Yet, obtaining plans that are both feasible (grounded in affordances) and cost-effective (in plan length), remains a challenge, despite recent progress. This contrasts with heuristic planning methods that employ domain knowledge (formalized in action models such as PDDL) and heuristic search to generate feasible, optimal plans. Inspired by this, we propose to combine the power of LLMs and heuristic planning by leveraging the world knowledge of LLMs and the principles of heuristic search. Our approach, SayCanPay, employs LLMs to generate actions (Say) guided by learnable domain knowledge, that evaluates actions' feasibility (Can) and long-term reward/payoff (Pay), and heuristic search to select the best sequence of actions. Our contributions are (1) a novel framing of the LLM planning problem in the context of heuristic planning, (2) integrating grounding and cost-effective elements into the generated plans, and (3) using heuristic search over actions. Our extensive evaluations show that our model surpasses other LLM planning approaches.",http://arxiv.org/abs/2308.12682v2,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']",['heuristics-optimization'],['heuristics-optimization']
TPTU: Large Language Model-based AI Agents for Task Planning and Tool Usage,"Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, Guoqing Du, Shiwei Shi, Hangyu Mao, Ziyue Li, Xingyu Zeng, Rui Zhao",2023-08-07,"With recent advancements in natural language processing, Large Language Models (LLMs) have emerged as powerful tools for various real-world applications. Despite their prowess, the intrinsic generative abilities of LLMs may prove insufficient for handling complex tasks which necessitate a combination of task planning and the usage of external tools. In this paper, we first propose a structured framework tailored for LLM-based AI Agents and discuss the crucial capabilities necessary for tackling intricate problems. Within this framework, we design two distinct types of agents (i.e., one-step agent and sequential agent) to execute the inference process. Subsequently, we instantiate the framework using various LLMs and evaluate their Task Planning and Tool Usage (TPTU) abilities on typical tasks. By highlighting key findings and challenges, our goal is to provide a helpful resource for researchers and practitioners to leverage the power of LLMs in their AI applications. Our study emphasizes the substantial potential of these models, while also identifying areas that need more investigation and improvement.",http://arxiv.org/abs/2308.03427v3,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'plan-generation']",['tool-integration'],['tool-integration']
New Interaction Paradigm for Complex EDA Software Leveraging GPT,"Boyu Han, Xinyu Wang, Yifan Wang, Junyu Yan, Yidong Tian",2023-07-27,"In the rapidly growing field of electronic design automation (EDA), professional software such as KiCad, Cadence , and Altium Designer provide increasingly extensive design functionalities. However, the intricate command structure and high learning curve create a barrier, particularly for novice printed circuit board (PCB) designers. This results in difficulties in selecting appropriate functions or plugins for varying design purposes, compounded by the lack of intuitive learning methods beyond traditional documentation, videos, and online forums. To address this challenge, an artificial intelligence (AI) interaction assist plugin for EDA software named SmartonAl is developed here, also KiCad is taken as the first example. SmartonAI is inspired by the HuggingGPT framework and employs large language models, such as GPT and BERT, to facilitate task planning and execution. On receiving a designer request, SmartonAI conducts a task breakdown and efficiently executes relevant subtasks, such as analysis of help documentation paragraphs and execution of different plugins, along with leveraging the built-in schematic and PCB manipulation functions in both SmartonAl itself and software. Our preliminary results demonstrate that SmartonAI can significantly streamline the PCB design process by simplifying complex commands into intuitive language-based interactions. By harnessing the powerful language capabilities of ChatGPT and the rich design functions of KiCad, the plugin effectively bridges the gap between complex EDA software and user-friendly interaction. Meanwhile, the new paradigm behind SmartonAI can also extend to other complex software systems, illustrating the immense potential of AI-assisted user interfaces in advancing digital interactions across various domains.",http://arxiv.org/abs/2307.14740v1,"cs.SE, cs.AI","['tool-integration', 'heuristics-optimization', 'model-construction', 'plan-generation']",['Unclassified'],['Unclassified'],['Unclassified'],['Unclassified']
SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Robot Task Planning,"Krishan Rana, Jesse Haviland, Sourav Garg, Jad Abou-Chakra, Ian Reid, Niko Suenderhauf",2023-07-12,"Large language models (LLMs) have demonstrated impressive results in developing generalist planning agents for diverse tasks. However, grounding these plans in expansive, multi-floor, and multi-room environments presents a significant challenge for robotics. We introduce SayPlan, a scalable approach to LLM-based, large-scale task planning for robotics using 3D scene graph (3DSG) representations. To ensure the scalability of our approach, we: (1) exploit the hierarchical nature of 3DSGs to allow LLMs to conduct a 'semantic search' for task-relevant subgraphs from a smaller, collapsed representation of the full graph; (2) reduce the planning horizon for the LLM by integrating a classical path planner and (3) introduce an 'iterative replanning' pipeline that refines the initial plan using feedback from a scene graph simulator, correcting infeasible actions and avoiding planning failures. We evaluate our approach on two large-scale environments spanning up to 3 floors and 36 rooms with 140 assets and objects and show that our approach is capable of grounding large-scale, long-horizon task plans from abstract, and natural language instruction for a mobile manipulator robot to execute. We provide real robot video demonstrations on our project page https://sayplan.github.io.",http://arxiv.org/abs/2307.06135v2,"cs.RO, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'plan-generation', 'language-translation', 'interactive-planning']","['plan-generation', 'interactive-planning']"
Grammar Prompting for Domain-Specific Language Generation with Large Language Models,"Bailin Wang, Zi Wang, Xuezhi Wang, Yuan Cao, Rif A. Saurous, Yoon Kim",2023-05-30,"Large language models (LLMs) can learn to perform a wide range of natural language tasks from just a handful of in-context examples. However, for generating strings from highly structured languages (e.g., semantic parsing to complex domain-specific languages), it is challenging for the LLM to generalize from just a few exemplars. We propose \emph{grammar prompting}, a simple approach to enable LLMs to use external knowledge and domain-specific constraints, expressed through a grammar in Backus--Naur Form (BNF), during in-context learning. Grammar prompting augments each demonstration example with a specialized grammar that is minimally sufficient for generating the particular output example, where the specialized grammar is a subset of the full DSL grammar. For inference, the LLM first predicts a BNF grammar given a test input, and then generates the output according to the rules of the grammar. Experiments demonstrate that grammar prompting can enable LLMs to perform competitively on a diverse set of DSL generation tasks, including semantic parsing (SMCalFlow, Overnight, GeoQuery), PDDL planning, and SMILES-based molecule generation.",http://arxiv.org/abs/2305.19234v3,"cs.CL, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'model-construction', 'interactive-planning', 'plan-generation']",['Unclassified'],['Unclassified'],['Unclassified']
Integrating Action Knowledge and LLMs for Task Planning and Situation Handling in Open Worlds,"Yan Ding, Xiaohan Zhang, Saeid Amiri, Nieqing Cao, Hao Yang, Andy Kaminski, Chad Esselink, Shiqi Zhang",2023-05-27,"Task planning systems have been developed to help robots use human knowledge (about actions) to complete long-horizon tasks. Most of them have been developed for ""closed worlds"" while assuming the robot is provided with complete world knowledge. However, the real world is generally open, and the robots frequently encounter unforeseen situations that can potentially break the planner's completeness. Could we leverage the recent advances on pre-trained Large Language Models (LLMs) to enable classical planning systems to deal with novel situations? This paper introduces a novel framework, called COWP, for open-world task planning and situation handling. COWP dynamically augments the robot's action knowledge, including the preconditions and effects of actions, with task-oriented commonsense knowledge. COWP embraces the openness from LLMs, and is grounded to specific domains via action knowledge. For systematic evaluations, we collected a dataset that includes 1,085 execution-time situations. Each situation corresponds to a state instance wherein a robot is potentially unable to complete a task using a solution that normally works. Experimental results show that our approach outperforms competitive baselines from the literature in the success rate of service tasks. Additionally, we have demonstrated COWP using a mobile manipulator. Supplementary materials are available at: https://cowplanning.github.io/",http://arxiv.org/abs/2305.17590v2,"cs.RO, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']",['Unclassified'],['Unclassified']
Understanding the Capabilities of Large Language Models for Automated Planning,"Vishal Pallagani, Bharath Muppasani, Keerthiram Murugesan, Francesca Rossi, Biplav Srivastava, Lior Horesh, Francesco Fabiano, Andrea Loreggia",2023-05-25,"Automated planning is concerned with developing efficient algorithms to generate plans or sequences of actions to achieve a specific goal in a given environment. Emerging Large Language Models (LLMs) can answer questions, write high-quality programming code, and predict protein folding, showcasing their versatility in solving various tasks beyond language-based problems. In this paper, we aim to explore how LLMs can also be used for automated planning. To do so, we seek to answer four key questions. Firstly, we want to understand the extent to which LLMs can be used for plan generation. Secondly, we aim to identify which pre-training data is most effective in facilitating plan generation. Thirdly, we investigate whether fine-tuning or prompting is a more effective approach for plan generation. Finally, we explore whether LLMs are capable of plan generalization. By answering these questions, the study seeks to shed light on the capabilities of LLMs in solving complex planning problems and provide insights into the most effective approaches for using LLMs in this context.",http://arxiv.org/abs/2305.16151v1,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']",['plan-generation'],['plan-generation']
Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning,"Lin Guan, Karthik Valmeekam, Sarath Sreedharan, Subbarao Kambhampati",2023-05-24,"There is a growing interest in applying pre-trained large language models (LLMs) to planning problems. However, methods that use LLMs directly as planners are currently impractical due to several factors, including limited correctness of plans, strong reliance on feedback from interactions with simulators or even the actual environment, and the inefficiency in utilizing human feedback. In this work, we introduce a novel alternative paradigm that constructs an explicit world (domain) model in planning domain definition language (PDDL) and then uses it to plan with sound domain-independent planners. To address the fact that LLMs may not generate a fully functional PDDL model initially, we employ LLMs as an interface between PDDL and sources of corrective feedback, such as PDDL validators and humans. For users who lack a background in PDDL, we show that LLMs can translate PDDL into natural language and effectively encode corrective feedback back to the underlying domain model. Our framework not only enjoys the correctness guarantee offered by the external planners but also reduces human involvement by allowing users to correct domain models at the beginning, rather than inspecting and correcting (through interactive prompting) every generated plan as in previous work. On two IPC domains and a Household domain that is more complicated than commonly used benchmarks such as ALFWorld, we demonstrate that GPT-4 can be leveraged to produce high-quality PDDL models for over 40 actions, and the corrected PDDL models are then used to successfully solve 48 challenging planning tasks. Resources, including the source code, are released at: https://guansuns.github.io/pages/llm-dm.",http://arxiv.org/abs/2305.14909v2,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'plan-generation', 'language-translation', 'interactive-planning']","['language-translation', 'interactive-planning']","['language-translation', 'interactive-planning']"
Generalized Planning in PDDL Domains with Pretrained Large Language Models,"Tom Silver, Soham Dan, Kavitha Srinivas, Joshua B. Tenenbaum, Leslie Pack Kaelbling, Michael Katz",2023-05-18,"Recent work has considered whether large language models (LLMs) can function as planners: given a task, generate a plan. We investigate whether LLMs can serve as generalized planners: given a domain and training tasks, generate a program that efficiently produces plans for other tasks in the domain. In particular, we consider PDDL domains and use GPT-4 to synthesize Python programs. We also consider (1) Chain-of-Thought (CoT) summarization, where the LLM is prompted to summarize the domain and propose a strategy in words before synthesizing the program; and (2) automated debugging, where the program is validated with respect to the training tasks, and in case of errors, the LLM is re-prompted with four types of feedback. We evaluate this approach in seven PDDL domains and compare it to four ablations and four baselines. Overall, we find that GPT-4 is a surprisingly powerful generalized planner. We also conclude that automated debugging is very important, that CoT summarization has non-uniform impact, that GPT-4 is far superior to GPT-3.5, and that just two training tasks are often sufficient for strong generalization.",http://arxiv.org/abs/2305.11014v2,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['tool-integration', 'plan-generation', 'language-translation', 'interactive-planning']",['plan-generation'],['plan-generation']
Learning to Reason over Scene Graphs: A Case Study of Finetuning GPT-2 into a Robot Language Model for Grounded Task Planning,"Georgia Chalvatzaki, Ali Younes, Daljeet Nandha, An Le, Leonardo F. R. Ribeiro, Iryna Gurevych",2023-05-12,"Long-horizon task planning is essential for the development of intelligent assistive and service robots. In this work, we investigate the applicability of a smaller class of large language models (LLMs), specifically GPT-2, in robotic task planning by learning to decompose tasks into subgoal specifications for a planner to execute sequentially. Our method grounds the input of the LLM on the domain that is represented as a scene graph, enabling it to translate human requests into executable robot plans, thereby learning to reason over long-horizon tasks, as encountered in the ALFRED benchmark. We compare our approach with classical planning and baseline methods to examine the applicability and generalizability of LLM-based planners. Our findings suggest that the knowledge stored in an LLM can be effectively grounded to perform long-horizon task planning, demonstrating the promising potential for the future application of neuro-symbolic planning methods in robotics.",http://arxiv.org/abs/2305.07716v1,"cs.RO, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['plan-generation', 'language-translation']","['plan-generation', 'language-translation']"
LLM+P: Empowering Large Language Models with Optimal Planning Proficiency,"Bo Liu, Yuqian Jiang, Xiaohan Zhang, Qiang Liu, Shiqi Zhang, Joydeep Biswas, Peter Stone",2023-04-22,"Large language models (LLMs) have demonstrated remarkable zero-shot generalization abilities: state-of-the-art chatbots can provide plausible answers to many common questions that arise in daily life. However, so far, LLMs cannot reliably solve long-horizon planning problems. By contrast, classical planners, once a problem is given in a formatted way, can use efficient search algorithms to quickly identify correct, or even optimal, plans. In an effort to get the best of both worlds, this paper introduces LLM+P, the first framework that incorporates the strengths of classical planners into LLMs. LLM+P takes in a natural language description of a planning problem, then returns a correct (or optimal) plan for solving that problem in natural language. LLM+P does so by first converting the language description into a file written in the planning domain definition language (PDDL), then leveraging classical planners to quickly find a solution, and then translating the found solution back into natural language. Along with LLM+P, we define a diverse set of different benchmark problems taken from common planning scenarios. Via a comprehensive set of experiments on these benchmark problems, we find that LLM+P is able to provide optimal solutions for most problems, while LLMs fail to provide even feasible plans for most problems.\footnote{The code and results are publicly available at https://github.com/Cranial-XIX/llm-pddl.git.",http://arxiv.org/abs/2304.11477v3,"cs.AI, cs.RO","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'model-construction', 'interactive-planning', 'plan-generation']",['language-translation'],['language-translation']
A Framework for Neurosymbolic Robot Action Planning using Large Language Models,"Alessio Capitanelli, Fulvio Mastrogiovanni",2023-03-01,"Symbolic task planning is a widely used approach to enforce robot autonomy due to its ease of understanding and deployment in robot architectures. However, techniques for symbolic task planning are difficult to scale in real-world, human-robot collaboration scenarios because of the poor performance in complex planning domains or when frequent re-planning is needed. We present a framework, Teriyaki, specifically aimed at bridging the gap between symbolic task planning and machine learning approaches. The rationale is training Large Language Models (LLMs), namely GPT-3, into a neurosymbolic task planner compatible with the Planning Domain Definition Language (PDDL), and then leveraging its generative capabilities to overcome a number of limitations inherent to symbolic task planners. Potential benefits include (i) a better scalability in so far as the planning domain complexity increases, since LLMs' response time linearly scales with the combined length of the input and the output, and (ii) the ability to synthesize a plan action-by-action instead of end-to-end, making each action available for execution as soon as it is generated instead of waiting for the whole plan to be available, which in turn enables concurrent planning and execution. Recently, significant efforts have been devoted by the research community to evaluate the cognitive capabilities of LLMs, with alternate successes. Instead, with Teriyaki we aim to provide an overall planning performance comparable to traditional planners in specific planning domains, while leveraging LLMs capabilities to build a look-ahead predictive planning model. Preliminary results in selected domains show that our method can: (i) solve 95.5% of problems in a test data set of 1,000 samples; (ii) produce plans up to 13.5% shorter than a traditional symbolic planner; (iii) reduce average overall waiting times for a plan availability by up to 61.4%",http://arxiv.org/abs/2303.00438v3,"cs.AI, cs.LG, cs.RO, I.2.6; I.2.8; I.2.9","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['plan-generation', 'language-translation']",['plan-generation']
"Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents","Zihao Wang, Shaofei Cai, Guanzhou Chen, Anji Liu, Xiaojian Ma, Yitao Liang",2023-02-03,"We investigate the challenge of task planning for multi-task embodied agents in open-world environments. Two main difficulties are identified: 1) executing plans in an open-world environment (e.g., Minecraft) necessitates accurate and multi-step reasoning due to the long-term nature of tasks, and 2) as vanilla planners do not consider how easy the current agent can achieve a given sub-task when ordering parallel sub-goals within a complicated plan, the resulting plan could be inefficient or even infeasible. To this end, we propose ""$\underline{D}$escribe, $\underline{E}$xplain, $\underline{P}$lan and $\underline{S}$elect"" ($\textbf{DEPS}$), an interactive planning approach based on Large Language Models (LLMs). DEPS facilitates better error correction on initial LLM-generated $\textit{plan}$ by integrating $\textit{description}$ of the plan execution process and providing self-$\textit{explanation}$ of feedback when encountering failures during the extended planning phases. Furthermore, it includes a goal $\textit{selector}$, which is a trainable module that ranks parallel candidate sub-goals based on the estimated steps of completion, consequently refining the initial plan. Our experiments mark the milestone of the first zero-shot multi-task agent that can robustly accomplish 70+ Minecraft tasks and nearly double the overall performances. Further testing reveals our method's general effectiveness in popularly adopted non-open-ended domains as well (i.e., ALFWorld and tabletop manipulation). The ablation and exploratory studies detail how our design beats the counterparts and provide a promising update on the $\texttt{ObtainDiamond}$ grand challenge with our approach. The code is released at https://github.com/CraftJarvis/MC-Planner.",http://arxiv.org/abs/2302.01560v3,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'model-construction', 'interactive-planning', 'plan-generation']",['plan-generation'],['plan-generation']
Plansformer: Generating Symbolic Plans using Transformers,"Vishal Pallagani, Bharath Muppasani, Keerthiram Murugesan, Francesca Rossi, Lior Horesh, Biplav Srivastava, Francesco Fabiano, Andrea Loreggia",2022-12-16,"Large Language Models (LLMs) have been the subject of active research, significantly advancing the field of Natural Language Processing (NLP). From BERT to BLOOM, LLMs have surpassed state-of-the-art results in various natural language tasks such as question answering, summarization, and text generation. Many ongoing efforts focus on understanding LLMs' capabilities, including their knowledge of the world, syntax, and semantics. However, extending the textual prowess of LLMs to symbolic reasoning has been slow and predominantly focused on tackling problems related to the mathematical field. In this paper, we explore the use of LLMs for automated planning - a branch of AI concerned with the realization of action sequences (plans) to achieve a goal, typically executed by intelligent agents, autonomous robots, and unmanned vehicles. We introduce Plansformer; an LLM fine-tuned on planning problems and capable of generating plans with favorable behavior in terms of correctness and length with reduced knowledge-engineering efforts. We also demonstrate the adaptability of Plansformer in solving different planning domains with varying complexities, owing to the transfer learning abilities of LLMs. For one configuration of Plansformer, we achieve ~97% valid plans, out of which ~95% are optimal for Towers of Hanoi - a puzzle-solving domain.",http://arxiv.org/abs/2212.08681v1,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['plan-generation', 'language-translation']",['plan-generation']
Robot Task Planning and Situation Handling in Open Worlds,"Yan Ding, Xiaohan Zhang, Saeid Amiri, Nieqing Cao, Hao Yang, Chad Esselink, Shiqi Zhang",2022-10-04,"Automated task planning algorithms have been developed to help robots complete complex tasks that require multiple actions. Most of those algorithms have been developed for ""closed worlds"" assuming complete world knowledge is provided. However, the real world is generally open, and the robots frequently encounter unforeseen situations that can potentially break the planner's completeness. This paper introduces a novel algorithm (COWP) for open-world task planning and situation handling that dynamically augments the robot's action knowledge with task-oriented common sense. In particular, common sense is extracted from Large Language Models based on the current task at hand and robot skills. For systematic evaluations, we collected a dataset that includes 561 execution-time situations in a dining domain, where each situation corresponds to a state instance of a robot being potentially unable to complete a task using a solution that normally works. Experimental results show that our approach significantly outperforms competitive baselines from the literature in the success rate of service tasks. Additionally, we have demonstrated COWP using a mobile manipulator. Supplementary materials are available at: https://cowplanning.github.io/",http://arxiv.org/abs/2210.01287v1,"cs.RO, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'language-translation', 'model-construction', 'interactive-planning', 'plan-generation']",['Unclassified'],['Unclassified']
PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning and Reasoning about Change,"Karthik Valmeekam, Matthew Marquez, Alberto Olmo, Sarath Sreedharan, Subbarao Kambhampati",2022-06-21,"Generating plans of action, and reasoning about change have long been considered a core competence of intelligent agents. It is thus no surprise that evaluating the planning and reasoning capabilities of large language models (LLMs) has become a hot topic of research. Most claims about LLM planning capabilities are however based on common sense tasks-where it becomes hard to tell whether LLMs are planning or merely retrieving from their vast world knowledge. There is a strong need for systematic and extensible planning benchmarks with sufficient diversity to evaluate whether LLMs have innate planning capabilities. Motivated by this, we propose PlanBench, an extensible benchmark suite based on the kinds of domains used in the automated planning community, especially in the International Planning Competition, to test the capabilities of LLMs in planning or reasoning about actions and change. PlanBench provides sufficient diversity in both the task domains and the specific planning capabilities. Our studies also show that on many critical capabilities-including plan generation-LLM performance falls quite short, even with the SOTA models. PlanBench can thus function as a useful marker of progress of LLMs in planning and reasoning.",http://arxiv.org/abs/2206.10498v4,"cs.CL, cs.AI","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'interactive-planning', 'plan-generation']","['heuristics-optimization', 'plan-generation']",['plan-generation']
A Review on Learning Planning Action Models for Socio-Communicative HRI,"Ankuj Arora, Humbert Fiorino, Damien Pellier, Sylvie Pesty",2018-10-22,"For social robots to be brought more into widespread use in the fields of companionship, care taking and domestic help, they must be capable of demonstrating social intelligence. In order to be acceptable, they must exhibit socio-communicative skills. Classic approaches to program HRI from observed human-human interactions fails to capture the subtlety of multimodal interactions as well as the key structural differences between robots and humans. The former arises due to a difficulty in quantifying and coding multimodal behaviours, while the latter due to a difference of the degrees of liberty between a robot and a human. However, the notion of reverse engineering from multimodal HRI traces to learn the underlying behavioral blueprint of the robot given multimodal traces seems an option worth exploring. With this spirit, the entire HRI can be seen as a sequence of exchanges of speech acts between the robot and human, each act treated as an action, bearing in mind that the entire sequence is goal-driven. Thus, this entire interaction can be treated as a sequence of actions propelling the interaction from its initial to goal state, also known as a plan in the domain of AI planning. In the same domain, this action sequence that stems from plan execution can be represented as a trace. AI techniques, such as machine learning, can be used to learn behavioral models (also known as symbolic action models in AI), intended to be reusable for AI planning, from the aforementioned multimodal traces. This article reviews recent machine learning techniques for learning planning action models which can be applied to the field of HRI with the intent of rendering robots as socio-communicative.",http://arxiv.org/abs/1810.09245v1,cs.AI,"['heuristics-optimization', 'tool-integration', 'language-translation', 'brain-inspired-planning', 'model-construction', 'multiagent-planning', 'interactive-planning', 'plan-generation']","['plan-generation', 'model-construction', 'language-translation', 'interactive-planning']",['Unclassified'],['Unclassified'],['Unclassified']
mGPT: A Probabilistic Planner Based on Heuristic Search,"B. Bonet, H. Geffner",2011-09-09,"We describe the version of the GPT planner used in the probabilistic track of the 4th International Planning Competition (IPC-4). This version, called mGPT, solves Markov Decision Processes specified in the PPDDL language by extracting and using different classes of lower bounds along with various heuristic-search algorithms. The lower bounds are extracted from deterministic relaxations where the alternative probabilistic effects of an action are mapped into different, independent, deterministic actions. The heuristic-search algorithms use these lower bounds for focusing the updates and delivering a consistent value function over all states reachable from the initial state and the greedy policy.",http://arxiv.org/abs/1109.2153v1,cs.AI,"['heuristics-optimization', 'model-construction', 'plan-generation']",['Unclassified'],['Unclassified'],['Unclassified'],['Unclassified']
